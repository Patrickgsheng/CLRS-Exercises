Although merge sort runs in Θ(n lg n) worst-case time and insertion sort runs
in Θ(n^2) worst-case time, the constant factors in insertion sort can make it
faster in practice for small problem sizes on many machines.  Thus, it makes
sense to *coarsen* the leaves of the recursion by using insertion sort within
merge-sort when subproblems become sufficiently small.  Consider a modification
to merge sort in which n/k sublists of length k are sorted using insertion sort
and then merged using the standard merging mechanism, where k is a value to be
determined.

a) Show that insertion sort can sort the n/k sublists, each of length k,
   in Θ(n k) worst-case time.

T(n) = n / k * T-INSERTION-SORT(k) = n / k * k^2 = n * k

b) Show how to merge the sublists in Θ(n lg (n / k)) worst-case time.

MERGE-INSERTION-SORT(A, p, r, k)
    if r - p > k
        q = ⌊(p + r) / 2⌋
        MERGE-INSERTION-SORT(A, p, q, k)
        MERGE-INSERTION-SORT(A, q+1, r, k)
        MERGE(A, p, q, r)
    else
        INSERTION-SORT(A)

c) Given that the modified algorithm runs in Θ(n k + n lg (n / k)) worst-case
   time, what is the largest value of k as a function of n for which the
   modified algorithm has the same running time as standard merge sort, in
   terms of Θ-notation?

k = Θ(lg n)

n lg n + n lg (n / lg n) =>
n lg n + n (lg n - lg (lg n)) =>
n lg n + n lg n - n lg (lg n) =>
2 n lg n - n lg (lg n) =>
n lg n   (by ignoring constants and lower order terms)

d) How should we choose k in practice?

By doing an analysis including instruction execution time to find the
value where k begins to provide improved efficiency.
